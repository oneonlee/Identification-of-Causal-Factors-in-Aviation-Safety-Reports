{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- References\n",
    "    - [\"19-04 BERT를 이용한 키워드 추출 : 키버트(KeyBERT)\", 딥 러닝을 이용한 자연어 처리 입문 (2022)](https://wikidocs.net/159467)\n",
    "    - [ukairia777 GitHub - tensorflow-nlp-tutorial/19. Topic Modeling (LDA, BERT-Based)\n",
    "/19-5. keybert_kor.ipynb](https://github.com/ukairia777/tensorflow-nlp-tutorial/blob/df3f84702cd4e00ec2319549a2f029c3b2d666f6/19.%20Topic%20Modeling%20(LDA%2C%20BERT-Based)/19-5.%20keybert_kor.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOmAceu1kWr9",
    "outputId": "8e239282-f098-4f05-b351-db7453f0f200"
   },
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_MODEL_PATH = 'jhgan/ko-sroberta-multitask'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90aIbIiLrqz3"
   },
   "source": [
    "특정 문서의 주요 정보를 이해하고자 할 때 키워드 추출을 통해서 입력 텍스트와 가장 관련이 있는 단어와 구문을 추출할 수 있습니다. 'Rake'나 'YAKE!'와 같은 키워드를 추출하는 데 사용할 수 있는 패키지가 이미 존재합니다. 그러나 이러한 모델은 일반적으로 텍스트의 통계적 특성에 기반하여 작동하며 의미적인 유사성에 대해서는 고려하지 않습니다. 의미적 유사성을 고려하기 위해서 여기서는 SBERT 임베딩을 활용하여 사용하기 쉬운 키워드 추출 알고리즘인 KeyBERT를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaxveAOApIru"
   },
   "source": [
    "# 1. 기본 KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d1eODWZ6kw2w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(doc):\n",
    "    processed_doc = doc.strip('\"').replace(\"\\n\", \" \").strip()\n",
    "    processed_doc = re.sub('\\s+', ' ', processed_doc)\n",
    "    \n",
    "    return processed_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(string):\n",
    "    return string.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YjY9MmrPkPbX"
   },
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "B737-700 항공기 항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게 설정하도록 지시를 받았다. 그러한 복행 기동은 복잡한 사안, 통찰력, 항공 우수성에도 전하여 쟁취하려는 항공 관리 철학 등이 뒤엉킨 총체적 난국과도 같은 상황을 야기 했다. 기장이 작성한 보고서에는 다음과 같이 기술되어 있다. ■접근관제소가 우리를 너무 가깝고 높게 유도하여 ILS 상에서 적절한 항로를 수립할 수 없었습니다. 저는 관제 승무원(PM)이었으며, 저는 부조종사에게 '1,000피트 정도 차이로 실패하게 될 것 입니다. '라고 말했습니다. 우리는 3,000피트 MSL에 위치해 있었고 조종 승무원은 다급히 플랩을 30도로 설정하고 있었습니다. 저는 접근관제소에게 '우리는 복행 기동을 실시하겠다'라고 말했습니다. 조종 승무원이 출력을 증가시켰지만, 항공기 노즈를 너무 높게 피치 업 시켜서 결국 'AIRSPEED' 경고가 발생하게 되었습니다. PF가 항공기 노즈를 낮춰서 피치를 어느 정도 바로잡기는 했지만 노즈가 다시 피치 업 되면서 두 번째 'AIRSPEED' 경고가 발생 하였습니다. 첫 번째 'AIRSPEED' 경고가 발생하자 저는 플랩 레버를 15도(제 생각에는)로 맞추고 있었습니다. 두 번째 경고가 발생했을 때 PF는 조종간을 힘껏 아래로 내려 비행 속도를 다시 증가시키려 했습니다. PF가 이러한 보다 과격한 기동을 사용하자, 저는 '수평을 유지 하세요'라고 말했습니다. 그는 수평을 유지했고 비행 속도도 증가하기 시작했습니다. 우리는 착륙 진입을 다시 시도하기 위해 진로를 다시 잡았고, 이번에는 아무런 사고도 없이 무사히 착륙할 수 있었습니다.\n",
    "\n",
    "[주요 원인]\n",
    "PF 및 내 자신의 조종 실수, 기장으로서 조종 제어를 맡지 않으려 한 점과 지극히 이례적이고 예측할 수 없었던 극적인 복행 기동 상황에서 적절할 조언을 제공할 준비가 되어 있지 않았던 점 등 부기장이 작성한 보고서에는 다음과 같이 기술되어 있다.\n",
    "■착륙 진입을 계속 시도하지 않았어야 했었습니다. Glideslope가 너무 낮다는 점이 명확하게 드러났을 때 제가 즉시 복행 기동을 실시했었어야 했습니다. 두 승무원들 사이의 교류가 단절되었던 점은 분명합니다. 한 명은 항공기를 조종하고 있었고 다른 한 명은 ATC와 교신하고 있었습니다. 복행 기동은 적시에 승무원 모두의 협력을 통해 이루어진 것이 아니었고, 그로 인해 오류가 발생하게 되었습니다. PM과 PF 사이의 조화도 이루어지지 않았습니다. 우리는 복행 기동을 자주 시도하는 편이 아니기 때문에 익숙하지 않을 수 있습니다. 우리는 차트에 복행 절차에 대한 과정을 작성해 놓긴 하지만, 머릿속으로 또는 구두로 해당 기동에 대해 점검해 보아야 할 것입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_doc = process_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNBysM0d3g4G",
    "outputId": "02bfa026-d955-417e-d8b7-256c7cde1ab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"B737-700 항공기 항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게 설정하도록 지시를 받았다. 그러한 복행 기동은 복잡한 사안, 통찰력, 항공 우수성에도 전하여 쟁취하려는 항공 관리 철학 등이 뒤엉킨 총체적 난국과도 같은 상황을 야기 했다. 기장이 작성한 보고서에는 다음과 같이 기술되어 있다. ■접근관제소가 우리를 너무 가깝고 높게 유도하여 ILS 상에서 적절한 항로를 수립할 수 없었습니다. 저는 관제 승무원(PM)이었으며, 저는 부조종사에게 '1,000피트 정도 차이로 실패하게 될 것 입니다. '라고 말했습니다. 우리는 3,000피트 MSL에 위치해 있었고 조종 승무원은 다급히 플랩을 30도로 설정하고 있었습니다. 저는 접근관제소에게 '우리는 복행 기동을 실시하겠다'라고 말했습니다. 조종 승무원이 출력을 증가시켰지만, 항공기 노즈를 너무 높게 피치 업 시켜서 결국 'AIRSPEED' 경고가 발생하게 되었습니다. PF가 항공기 노즈를 낮춰서 피치를 어느 정도 바로잡기는 했지만 노즈가 다시 피치 업 되면서 두 번째 'AIRSPEED' 경고가 발생 하였습니다. 첫 번째 'AIRSPEED' 경고가 발생하자 저는 플랩 레버를 15도(제 생각에는)로 맞추고 있었습니다. 두 번째 경고가 발생했을 때 PF는 조종간을 힘껏 아래로 내려 비행 속도를 다시 증가시키려 했습니다. PF가 이러한 보다 과격한 기동을 사용하자, 저는 '수평을 유지 하세요'라고 말했습니다. 그는 수평을 유지했고 비행 속도도 증가하기 시작했습니다. 우리는 착륙 진입을 다시 시도하기 위해 진로를 다시 잡았고, 이번에는 아무런 사고도 없이 무사히 착륙할 수 있었습니다. [주요 원인] PF 및 내 자신의 조종 실수, 기장으로서 조종 제어를 맡지 않으려 한 점과 지극히 이례적이고 예측할 수 없었던 극적인 복행 기동 상황에서 적절할 조언을 제공할 준비가 되어 있지 않았던 점 등 부기장이 작성한 보고서에는 다음과 같이 기술되어 있다. ■착륙 진입을 계속 시도하지 않았어야 했었습니다. Glideslope가 너무 낮다는 점이 명확하게 드러났을 때 제가 즉시 복행 기동을 실시했었어야 했습니다. 두 승무원들 사이의 교류가 단절되었던 점은 분명합니다. 한 명은 항공기를 조종하고 있었고 다른 한 명은 ATC와 교신하고 있었습니다. 복행 기동은 적시에 승무원 모두의 협력을 통해 이루어진 것이 아니었고, 그로 인해 오류가 발생하게 되었습니다. PM과 PF 사이의 조화도 이루어지지 않았습니다. 우리는 복행 기동을 자주 시도하는 편이 아니기 때문에 익숙하지 않을 수 있습니다. 우리는 차트에 복행 절차에 대한 과정을 작성해 놓긴 하지만, 머릿속으로 또는 구두로 해당 기동에 대해 점검해 보아야 할 것입니다.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc = \" \".join(processed_doc.split(' '))\n",
    "tokenized_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Upr1ps4qswAh"
   },
   "source": [
    "여기서는 사이킷런의 CountVectorizer를 사용하여 단어를 추출합니다.  CountVectorizer를 사용하는 이유는 n_gram_range의 인자를 사용하면 단쉽게 n-gram을 추출할 수 있기 때문입니다. 예를 들어, (2, 3)으로 설정하면 결과 후보는 2개의 단어를 한 묶음으로 간주하는 bigram과 3개의 단어를 한 묶음으로 간주하는 trigram을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0SC908jkEfz",
    "outputId": "11b33665-9003-449a-d07e-d5efe77f48ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram 개수 : 1846\n",
      "trigram 다섯개만 출력 : [\"'1,000피트 정도 차이로\" \"'1,000피트 정도 차이로 실패하게\" \"'1,000피트 정도 차이로 실패하게 될\"\n",
      " \"'1,000피트 정도 차이로 실패하게 될 것\" \"'1,000피트 정도 차이로 실패하게 될 것 입니다.\"]\n"
     ]
    }
   ],
   "source": [
    "n_gram_range = (3, 8)\n",
    "\n",
    "count = CountVectorizer(ngram_range=n_gram_range, lowercase=False, tokenizer=tokenizer, token_pattern=None).fit([tokenized_doc])\n",
    "candidates = count.get_feature_names_out()\n",
    "\n",
    "print('trigram 개수 :',len(candidates))\n",
    "print('trigram 다섯개만 출력 :',candidates[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7Dqv6jwv94E"
   },
   "source": [
    "다음으로 이제 문서와 문서로부터 추출한 키워드들을 SBERT를 통해서 수치화 할 차례입니다. 한국어를 포함하고 있는 다국어 SBERT를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jhgan/ko-sroberta-multitask'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HUGGINGFACE_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zGZKkdNdkUF_"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer(HUGGINGFACE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UTrVhm8349Cc"
   },
   "outputs": [],
   "source": [
    "doc_embedding = model.encode([doc])\n",
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9KGcs62p5OG"
   },
   "source": [
    "이제 문서와 가장 유사한 키워드들을 추출합니다. 여기서는 문서와 가장 유사한 키워드들은 문서를 대표하기 위한 좋은 키워드라고 가정합니다. 상위 5개의 키워드를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8l3aJzWTkpgG"
   },
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7PkJYUAmOWN",
    "outputId": "8c21bc7d-a07a-4e31-e2b2-1c2ccfd22c96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['기동 중 ATC로부터 고도를 높게 설정하도록 지시를 받았다.',\n",
       " '복행 기동 중 ATC로부터 고도를 높게 설정하도록 지시를',\n",
       " '승무원들은 복행 기동 중 ATC로부터 고도를 높게 설정하도록',\n",
       " '항공기 항공 승무원들은 복행 기동 중 ATC로부터 고도를',\n",
       " '항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4HPcJOxmMxt"
   },
   "source": [
    "5개의 키워드가 출력되는데, 이들의 의미가 좀 비슷해보입니다. 비슷한 의미의 키워드들이 리턴되는 데는 이유가 있습니다. 당연히 이 키워드들이 문서를 가장 잘 나타내고 있기 때문입니다. 만약, 지금 출력한 것보다는 좀 더 다양한 의미의 키워드들이 출력된다면 이들을 그룹으로 본다는 관점에서는 어쩌면 해당 키워드들이 문서를 잘 나타낼 가능성이 적을 수도 있습니다. 따라서 키워드들을 다양하게 출력하고 싶다면 키워드 선정의 정확성과 키워드들의 다양성 사이의 미묘한 균형이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HgqGxytwtFI"
   },
   "source": [
    "여기서는 다양한 키워드들을 얻기 위해서 두 가지 알고리즘을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AupvVbihwy4Z"
   },
   "source": [
    "* Max Sum Similarity  \n",
    "* Maximal Marginal Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoXd7eWFlzVx"
   },
   "source": [
    "# 2. Max Sum Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOMeOmkLl2oJ"
   },
   "source": [
    "데이터 쌍 사이의 최대 합 거리는 데이터 쌍 간의 거리가 최대화되는 데이터 쌍으로 정의됩니다. 여기서의 의도는 후보 간의 유사성을 최소화하면서 문서와의 후보 유사성을 극대화하고자 하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7I4MpmMhk2JS"
   },
   "outputs": [],
   "source": [
    "def max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n, nr_candidates):\n",
    "    # 문서와 각 키워드들 간의 유사도\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, \n",
    "                                            candidate_embeddings)\n",
    "\n",
    "    # 코사인 유사도에 기반하여 키워드들 중 상위 top_n개의 단어를 pick.\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # 각 키워드들 중에서 가장 덜 유사한 키워드들간의 조합을 계산\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    return [words_vals[idx] for idx in candidate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSHRT4GyrU6T"
   },
   "source": [
    "이를 위해 상위 10개의 키워드를 선택하고 이 10개 중에서 서로 가장 유사성이 낮은 5개를 선택합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVEwuvdtoNbl"
   },
   "source": [
    "낮은 nr_candidates를 설정하면 결과는 출력된 키워드 5개는 기존의 코사인 유사도만 사용한 것과 매우 유사한 것으로 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8HbW4xvnw6S",
    "outputId": "015f001e-0eff-45a3-a3bd-47724ef01dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATC로부터 고도를 높게 설정하도록 지시를 받았다. 그러한 복행',\n",
       " '항공기 항공 승무원들은 복행 기동 중 ATC로부터',\n",
       " 'B737-700 항공기 항공 승무원들은 복행 기동 중 ATC로부터',\n",
       " '기동 중 ATC로부터 고도를 높게 설정하도록 지시를 받았다.',\n",
       " '항공기 항공 승무원들은 복행 기동 중 ATC로부터 고도를']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=5, nr_candidates=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyENsqxKoN39"
   },
   "source": [
    "그러나 상대적으로 높은 nr_candidates는 더 다양한 키워드 5개를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELoogEc9oKyc",
    "outputId": "36ed2d69-9e2d-45aa-cd92-ce1a07cc5866"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B737-700 항공기 항공 승무원들은 복행 기동',\n",
       " '그러한 복행 기동은 복잡한 사안, 통찰력, 항공',\n",
       " '중 ATC로부터 고도를 높게 설정하도록 지시를 받았다.',\n",
       " '위치해 있었고 조종 승무원은 다급히',\n",
       " '중 ATC로부터 고도를 높게 설정하도록 지시를 받았다. 그러한']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=5, nr_candidates=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8TJsvU-p1a3"
   },
   "source": [
    "# 3. Maximal Marginal Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6Oc7LwspRCs"
   },
   "source": [
    "결과를 다양화하는 마지막 방법은 MMR(Maximum Limit Relegance)입니다. MMR은 텍스트 요약 작업에서 중복을 최소화하고 결과의 다양성을 극대화하기 위해 노력합니다. 참고 할 수 있는 자료로 EmbedRank(https://arxiv.org/pdf/1801.04470.pdf) 라는 키워드 추출 알고리즘은 키워드를 다양화하는 데 사용할 수 있는 MMR을 구현했습니다. 먼저 문서와 가장 유사한 키워드를 선택합니다. 그런 다음 문서와 유사하고 이미 선택된 키워드와 유사하지 않은 새로운 후보를 반복적으로 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ft7LAjDXonB_"
   },
   "outputs": [],
   "source": [
    "def mmr(doc_embedding, candidate_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # 문서와 각 키워드들 간의 유사도가 적혀있는 리스트\n",
    "    word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    word_similarity = cosine_similarity(candidate_embeddings)\n",
    "\n",
    "    # 문서와 가장 높은 유사도를 가진 키워드의 인덱스를 추출.\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # keywords_idx = [2]\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "\n",
    "    # 가장 높은 유사도를 가진 키워드의 인덱스를 제외한 문서의 인덱스들\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # ==> candidates_idx = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10 ... 중략 ...]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    # 최고의 키워드는 이미 추출했으므로 top_n-1번만큼 아래를 반복.\n",
    "    # ex) top_n = 5라면, 아래의 loop는 4번 반복됨.\n",
    "    for _ in range(top_n - 1):\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # MMR을 계산\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # keywords & candidates를 업데이트\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPExUo11o213"
   },
   "source": [
    "만약 우리가 상대적으로 낮은 diversity 값을 설정한다면, 결과는 기존의 코사인 유사도만 사용한 것과 매우 유사한 것으로 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfxryZSOopAy",
    "outputId": "7356d661-5598-4193-b79a-d741f71b3313"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '적절한 항로를 수립할 수 없었습니다. 저는 관제 승무원(PM)이었으며,',\n",
       " '기동 중 ATC로부터 고도를 높게 설정하도록 지시를 받았다.',\n",
       " '위치해 있었고 조종 승무원은 다급히',\n",
       " '받았다. 그러한 복행 기동은 복잡한 사안, 통찰력, 항공']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '적절한 항로를 수립할 수 없었습니다. 저는 관제 승무원(PM)이었으며,',\n",
       " '높게 설정하도록 지시를 받았다. 그러한 복행 기동은 복잡한',\n",
       " '위치해 있었고 조종 승무원은 다급히',\n",
       " '쟁취하려는 항공 관리 철학 등이 뒤엉킨 총체적 난국과도']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '적절한 항로를 수립할 수 없었습니다. 저는 관제 승무원(PM)이었으며,',\n",
       " '상황을 야기 했다. 기장이 작성한 보고서에는 다음과',\n",
       " '쟁취하려는 항공 관리 철학 등이 뒤엉킨 총체적 난국과도',\n",
       " '있었고 조종 승무원은 다급히 플랩을 30도로 설정하고 있었습니다.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '난국과도 같은 상황을 야기 했다. 기장이 작성한 보고서에는',\n",
       " '적절한 항로를 수립할 수 없었습니다. 저는 관제 승무원(PM)이었으며,',\n",
       " '높게 설정하도록 지시를 받았다.',\n",
       " '전하여 쟁취하려는 항공 관리 철학 등이 뒤엉킨 총체적']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '수립할 수 없었습니다. 저는',\n",
       " '난국과도 같은 상황을 야기 했다. 기장이 작성한 보고서에는',\n",
       " \"다급히 플랩을 30도로 설정하고 있었습니다. 저는 접근관제소에게 '우리는\",\n",
       " '승무원들 사이의 교류가 단절되었던 점은']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL_gQ3Rlo57T"
   },
   "source": [
    "그러나 상대적으로 높은 diversity값은 다양한 키워드 5개를 만들어냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlMapb1covnK",
    "outputId": "092b28ef-20ba-4d22-f09c-066ff938cc87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '수립할 수 없었습니다. 저는',\n",
       " '보고서에는 다음과 같이 기술되어 있다.',\n",
       " '15도(제 생각에는)로 맞추고',\n",
       " '승무원들 사이의 교류가 단절되었던 점은 분명합니다.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '수립할 수 없었습니다. 저는',\n",
       " 'Glideslope가 너무 낮다는',\n",
       " '보고서에는 다음과 같이 기술되어 있다.',\n",
       " '그는 수평을 유지했고']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '사이의 교류가 단절되었던 점은 분명합니다.',\n",
       " '및 내 자신의',\n",
       " 'Glideslope가 너무 낮다는',\n",
       " '두 번째 경고가 발생했을 때 PF는']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항공 승무원들은 복행 기동 중 ATC로부터 고도를 높게',\n",
       " '사이의 교류가 단절되었던 점은 분명합니다.',\n",
       " '및 내 자신의',\n",
       " 'Glideslope가 너무 낮다는',\n",
       " '두 번째 경고가 발생했을 때 PF는']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(doc_embedding, candidate_embeddings, candidates, top_n=5, diversity=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 중간 정리\n",
    "결론적으로, 테스트 케이스에 대해서는 **Max Sum Similarity** (`nr_candidates=30`)의 성능이 가장 우수한 것을 확인하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 과정을 정리하여 **document를 입력으로 받고, keyphrase를 반환하는 함수**를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "HUGGINGFACE_MODEL_PATH = 'jhgan/ko-sroberta-multitask'\n",
    "model = SentenceTransformer(HUGGINGFACE_MODEL_PATH)\n",
    "\n",
    "def process_doc(doc):\n",
    "    processed_doc = doc.strip('\"').replace(\"\\n\", \" \").strip()\n",
    "    processed_doc = re.sub('\\s+', ' ', processed_doc)\n",
    "    \n",
    "    return processed_doc\n",
    "\n",
    "def tokenizer(string):\n",
    "    return string.split(\" \")\n",
    "\n",
    "def mmr(doc_embedding, candidate_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # 문서와 각 키워드들 간의 유사도가 적혀있는 리스트\n",
    "    word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    word_similarity = cosine_similarity(candidate_embeddings)\n",
    "\n",
    "    # 문서와 가장 높은 유사도를 가진 키워드의 인덱스를 추출.\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # keywords_idx = [2]\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "\n",
    "    # 가장 높은 유사도를 가진 키워드의 인덱스를 제외한 문서의 인덱스들\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # ==> candidates_idx = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10 ... 중략 ...]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    # 최고의 키워드는 이미 추출했으므로 top_n-1번만큼 아래를 반복.\n",
    "    # ex) top_n = 5라면, 아래의 loop는 4번 반복됨.\n",
    "    for _ in range(top_n - 1):\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # MMR을 계산\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # keywords & candidates를 업데이트\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_keyphrases(doc, model=SentenceTransformer(HUGGINGFACE_MODEL_PATH), n_gram_range=(1,10), keyword_top_n=5, mss_nr_candidates=30):\n",
    "    processed_doc = process_doc(doc)\n",
    "    tokenized_doc = \" \".join(processed_doc.split(' '))\n",
    "    \n",
    "    count = CountVectorizer(ngram_range=n_gram_range, lowercase=False, tokenizer=tokenizer, token_pattern=None).fit([tokenized_doc])\n",
    "\n",
    "    candidates = count.get_feature_names_out()\n",
    "\n",
    "    doc_embedding = model.encode([doc])\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "    # keyphrases_list = mmr(doc_embedding, candidate_embeddings, candidates, top_n=keyword_top_n, diversity=mmr_diversity)    \n",
    "    keyphrases_list = max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=keyword_top_n, nr_candidates=mss_nr_candidates)    \n",
    "    \n",
    "    return keyphrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "아내에게 집에서 저녁식사를 하겠다고 하고, 집을 나선 헬리콥터 조종사는 '모두를 행복하게' 해줄 생각으로 집으로 돌아가기로 마음먹었지만 그 결정은 그다지 현명하지 못한 결정이 되어버렸다. 나는 헬리콥터를 집 뒤에 있는 마을 공터에 착륙시켰다. 공터 면적은 충분히 넓었고, 착륙은 교과서대로 진행하였으며, 착륙장소 주변엔 아무도 없었다. 같은 장소는 아니지만 전에도 아무 문제없이 착륙해 본 경험이 있어서 걱정 없이 착륙했는데. 착륙하고 보니 큰 일이 벌어져 있었다. \n",
    "지나가던 구급차가 내 헬리콥터가 착륙하는 장면을 보고는 경찰서에 추락신고를 한 것이다. 수 분만에 경찰차, 소방차, 기자들이 모여들었다. \n",
    "단지 가족과 저녁식사를 하려했다는 이유는 관계당국에 설득력 있는 이유가 되지 못했고 여러 가지 주정부 법에 따라 벌금형이 내려졌다. \n",
    "착륙 전 충분한 '주의'를 기울였음에도 불구하고 FAR91.13 조차도 위반했다고 한다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"헬리콥터 조종사는 '모두를 행복하게' 해줄 생각으로 집으로 돌아가기로 마음먹었지만 그\",\n",
       " \"하고, 집을 나선 헬리콥터 조종사는 '모두를 행복하게' 해줄 생각으로 집으로\",\n",
       " '그다지 현명하지 못한 결정이 되어버렸다. 나는 헬리콥터를 집 뒤에',\n",
       " '헬리콥터를 집 뒤에 있는 마을 공터에 착륙시켰다. 공터 면적은',\n",
       " '헬리콥터를 집 뒤에 있는 마을 공터에 착륙시켰다. 공터 면적은 충분히']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_keyphrases(doc, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 테스트셋 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/rawdata/GYRO_testset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 219/219 [15:45<00:00,  4.32s/it]\n"
     ]
    }
   ],
   "source": [
    "predicted_keyphrases_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    doc = df[\"본문\"][i]\n",
    "    predicted_keyphrase = doc_to_keyphrases(doc, model=model)\n",
    "    predicted_keyphrases_list.append('\"' + '\", \"'.join(predicted_keyphrase) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"KeyBERT 예측 키워드\"] = predicted_keyphrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/prediction/KeySRoBERTa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "KeyBert_kor",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
