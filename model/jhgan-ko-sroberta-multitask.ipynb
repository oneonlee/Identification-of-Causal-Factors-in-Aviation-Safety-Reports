{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a048f8-3019-4e7e-9f38-8d96be9a8525",
   "metadata": {},
   "source": [
    "# SRoBERTa의 전이학습을 활용한 보고서 원인 추출 모델 개발"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebbb7be-282b-4090-9a43-87095affe1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_MODEL_PATH = 'jhgan/ko-sroberta-multitask'\n",
    "GPU_NUM = 0\n",
    "SEED = 42\n",
    "\n",
    "MODEL_PATH = f'{HUGGINGFACE_MODEL_PATH.replace(\"/\", \"-\")}/{HUGGINGFACE_MODEL_PATH.replace(\"/\", \"-\")}.pt'\n",
    "\n",
    "num_epochs = 200\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "MIN_NGRAM = 3\n",
    "MAX_NGRAM = 8\n",
    "\n",
    "SEQUENCE_MATCHER_THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b7485-14de-4fcf-aea3-922c2d89cd27",
   "metadata": {},
   "source": [
    "## (0) 기본 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12a1c8c-1b17-4747-9764-3691614dea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= f\"{GPU_NUM}\"  # Set the GPU number to use\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148ac4cb-4af9-440a-9da6-64f7ea987069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b00dfb-4953-434b-b752-8279b6f70816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 및 평가를 위한 라이브러리\n",
    "from sklearn.feature_extraction.text import CountVectorizer # CountVectorizer를 사용하는 이유는 n_gram_range의 인자를 사용하면 단쉽게 n-gram을 추출할 수 있기 때문입니다. \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(predict, ground):\n",
    "    return SequenceMatcher(None, predict, ground).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66218a50-fd76-42b0-aec7-f6771281799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if device =='cuda':\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942c6f6-f0e0-463b-ad64-e2cdbbe1bed6",
   "metadata": {},
   "source": [
    "### 사전학습 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776fa5df-6b41-40a4-b0f1-b7778f1a1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_model=SentenceTransformer(HUGGINGFACE_MODEL_PATH, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92473b85-42ae-409e-b6b6-845b4b3b95f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (1) 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7e065-f31e-482c-b32a-1003b7cd7590",
   "metadata": {},
   "source": [
    "### (1-1) 훈련 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a85cc3-b796-413b-a7da-1d77d5d775c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/rawdata/GYRO_trainset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6ddc3b-aaff-439c-bd77-7c6e43e49f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>근거</th>\n",
       "      <th>사고명</th>\n",
       "      <th>본문</th>\n",
       "      <th>원인 키워드</th>\n",
       "      <th>원인</th>\n",
       "      <th>발생지표</th>\n",
       "      <th>요약</th>\n",
       "      <th>재발방지대책</th>\n",
       "      <th>조치결과</th>\n",
       "      <th>DATA</th>\n",
       "      <th>비고</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>398.00</td>\n",
       "      <td>GYRO 92호</td>\n",
       "      <td>접근 중 절차고도 미준수</td>\n",
       "      <td>인천공항에 착륙을 위해 고도 약 12,000ft에서 강하 접근 중 Seoul App...</td>\n",
       "      <td>\"300ft가 낮은 4,800ft로 통과하였음\"</td>\n",
       "      <td>O 발견동기:FIX 통과 직전에 고도계를 확인하는 과정에서 발견. \\nO 발생요인:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>550.00</td>\n",
       "      <td>GYRO 110호</td>\n",
       "      <td>APU FIRE MESSAGE 시현 관련 정비조치 사례</td>\n",
       "      <td>zz공항에서 비행을 준비 중 FIRE LOOP 1 APU START MASSAGE가...</td>\n",
       "      <td>\"FIRE LOOP 1 APU START MASSAGE가 시현되어\", \"FIRE A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>166.00</td>\n",
       "      <td>GYRO 39호</td>\n",
       "      <td>TAIL-SKID 마모</td>\n",
       "      <td>◆ 경위 \\n제주 Runway24 ILS로 착륙 시(바람: 320/22) 고도 10...</td>\n",
       "      <td>\"Nose up 되는 것을 인지하고 막는 순간 Action이 늦었음.\", \"Powe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1,185.00</td>\n",
       "      <td>GYRO 126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>홍콩공항에서 RWY 07R로 이륙하기 위하여 TAXIWAY ON 'K'에서 TWR로...</td>\n",
       "      <td>\"'K1까지 TAXI 하라'는 것으로 오인하여 'K1'까지 진입하였음\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>984.00</td>\n",
       "      <td>GYRO 146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>짧은 비행이었지만, 난기류가 심한 날씨였다. 순항고도에 이르자 기장은 좌석벨트 지시...</td>\n",
       "      <td>\"기장이나와 뒤편에 위치해있던 객실승무원의 보고에 귀를 기울이지 않았다는 것이다.\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx         근거                             사고명  \\\n",
       "869    398.00   GYRO 92호                   접근 중 절차고도 미준수   \n",
       "870    550.00  GYRO 110호  APU FIRE MESSAGE 시현 관련 정비조치 사례   \n",
       "871    166.00   GYRO 39호                    TAIL-SKID 마모   \n",
       "872  1,185.00   GYRO 126                             NaN   \n",
       "873    984.00   GYRO 146                             NaN   \n",
       "\n",
       "                                                    본문  \\\n",
       "869  인천공항에 착륙을 위해 고도 약 12,000ft에서 강하 접근 중 Seoul App...   \n",
       "870  zz공항에서 비행을 준비 중 FIRE LOOP 1 APU START MASSAGE가...   \n",
       "871  ◆ 경위 \\n제주 Runway24 ILS로 착륙 시(바람: 320/22) 고도 10...   \n",
       "872  홍콩공항에서 RWY 07R로 이륙하기 위하여 TAXIWAY ON 'K'에서 TWR로...   \n",
       "873  짧은 비행이었지만, 난기류가 심한 날씨였다. 순항고도에 이르자 기장은 좌석벨트 지시...   \n",
       "\n",
       "                                                원인 키워드  \\\n",
       "869                         \"300ft가 낮은 4,800ft로 통과하였음\"   \n",
       "870  \"FIRE LOOP 1 APU START MASSAGE가 시현되어\", \"FIRE A...   \n",
       "871  \"Nose up 되는 것을 인지하고 막는 순간 Action이 늦었음.\", \"Powe...   \n",
       "872            \"'K1까지 TAXI 하라'는 것으로 오인하여 'K1'까지 진입하였음\"   \n",
       "873     \"기장이나와 뒤편에 위치해있던 객실승무원의 보고에 귀를 기울이지 않았다는 것이다.\"   \n",
       "\n",
       "                                                    원인 발생지표   요약 재발방지대책 조치결과  \\\n",
       "869  O 발견동기:FIX 통과 직전에 고도계를 확인하는 과정에서 발견. \\nO 발생요인:...  NaN  NaN    NaN  NaN   \n",
       "870                                                NaN  NaN  NaN    NaN  NaN   \n",
       "871                                                NaN  NaN  NaN    NaN  NaN   \n",
       "872                                                NaN  NaN  NaN    NaN  NaN   \n",
       "873                                                NaN  NaN  NaN    NaN  NaN   \n",
       "\n",
       "     DATA   비고  \n",
       "869   NaN  NaN  \n",
       "870   NaN  NaN  \n",
       "871   NaN  NaN  \n",
       "872   NaN  NaN  \n",
       "873   NaN  NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069f585-83df-4e85-be5c-1daf8bb69e20",
   "metadata": {},
   "source": [
    "### (1-2) `train_df`를 **페어 데이터셋**으로 변환하기\n",
    "- 페어 데이터셋의 구성\n",
    "    - '본문' - 'phrase' - '이진 라벨'\n",
    "        - '이진 라벨'의 의미 : 'phrase'가 '본문'의 원인인지 아닌지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aac2b40-ae6f-4cc6-b07f-afc39e97c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(doc):\n",
    "    processed_doc = doc.strip('\"').replace(\"\\n\", \" \").strip()\n",
    "    processed_doc = re.sub('\\s+', ' ', processed_doc)\n",
    "    \n",
    "    return processed_doc\n",
    "\n",
    "def tokenizer(string):\n",
    "    return string.split(\" \")\n",
    "\n",
    "def doc_to_candidate_phrase(doc, n_gram_range=(MIN_NGRAM, MAX_NGRAM)):\n",
    "    # 보고서를 입력으로 받으면,\n",
    "    # 보고서에서 후보 phrase를 추출하여 반환하는 함수\n",
    "    \n",
    "    processed_doc = process_doc(doc)\n",
    "    tokenized_doc = \" \".join(processed_doc.split(' '))\n",
    "    \n",
    "    count = CountVectorizer(ngram_range=n_gram_range, lowercase=False, tokenizer=tokenizer, token_pattern=None).fit([tokenized_doc])\n",
    "    candidates = count.get_feature_names_out()\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1652a2-96ba-4183-9646-d9360abbd1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'MAYDAY, MAYDAY, MAYDAY.\", \"'MAYDAY, MAYDAY, MAYDAY. ABC\",\n",
       "       \"'MAYDAY, MAYDAY, MAYDAY. ABC 유도로에서\", ...,\n",
       "       '힘으로 인해 의자 사이로 넘어졌다. 그러자', '힘으로 인해 의자 사이로 넘어졌다. 그러자 그는',\n",
       "       '힘으로 인해 의자 사이로 넘어졌다. 그러자 그는 내'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_candidate_phrase(train_df[\"본문\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5e5af4-85dd-475d-b2c7-1435b8ee1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pair_dataset(df):\n",
    "    pair_dataset = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        doc = df[\"본문\"][i]\n",
    "        candidates = doc_to_candidate_phrase(doc)    \n",
    "        gold_standards = df[\"원인 키워드\"][i]\n",
    "\n",
    "        for candidate_phrase in candidates:\n",
    "            binary_label = 0\n",
    "            for gold_standard in gold_standards:\n",
    "                # match 기법 1\n",
    "                # candidate_phrase가 gold_standard와 정확히 일치할 때만 인정\n",
    "                if candidate_phrase == gold_standard: \n",
    "                    binary_label = 1\n",
    "                    break\n",
    "\n",
    "                # match 기법 1\n",
    "                # candidate_phrase가 gold_standard와 정확히 일치할 때만 인정\n",
    "                elif similar(candidate_phrase, gold_standard) >= SEQUENCE_MATCHER_THRESHOLD:\n",
    "                    binary_label = 1\n",
    "                    break\n",
    "\n",
    "            pair_dataset.append({'i': i, 'doc_idx': df[\"idx\"][i], 'candidate': candidate_phrase, 'binary_label': binary_label})\n",
    "            \n",
    "    pair_dataset_df = pd.DataFrame(data=pair_dataset,\n",
    "                              columns=['i', 'doc_idx', 'candidate', 'binary_label'])\n",
    "    \n",
    "    return pair_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b182af88-1ce0-47a1-bd85-c12104d6eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c73a965-737f-4c75-a7b9-040519e01db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(f'../data/pair_dataset/{MODE}_pair_dataset_df_{str(SEQUENCE_MATCHER_THRESHOLD).replace(\".\", \"_\")}.pkl'):\n",
    "    with open(f'../data/pair_dataset/{MODE}_pair_dataset_df_{str(SEQUENCE_MATCHER_THRESHOLD).replace(\".\", \"_\")}.pkl', 'rb') as f:\n",
    "        train_pair_dataset_df = pickle.load(f)\n",
    "else:\n",
    "    train_pair_dataset_df = make_pair_dataset(train_df)\n",
    "    with open(f'../data/pair_dataset/{MODE}_pair_dataset_df_{str(SEQUENCE_MATCHER_THRESHOLD).replace(\".\", \"_\")}.pkl', 'wb') as f:\n",
    "        pickle.dump(train_pair_dataset_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f59709a2-d014-476e-86a8-b147bd297252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>doc_idx</th>\n",
       "      <th>candidate</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>'MAYDAY,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>'MAYDAY, MAYDAY,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>'MAYDAY, MAYDAY, MAYDAY.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>'MAYDAY, MAYDAY, MAYDAY. ABC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>'MAYDAY, MAYDAY, MAYDAY. ABC 유도로에서</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038646</th>\n",
       "      <td>873</td>\n",
       "      <td>984.00</td>\n",
       "      <td>했다. 내가 말하고 싶은 것은 기장이나와</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038647</th>\n",
       "      <td>873</td>\n",
       "      <td>984.00</td>\n",
       "      <td>했다. 내가 말하고 싶은 것은 기장이나와 뒤편에</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038648</th>\n",
       "      <td>873</td>\n",
       "      <td>984.00</td>\n",
       "      <td>했다. 내가 말하고 싶은 것은 기장이나와 뒤편에 위치해있던</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038649</th>\n",
       "      <td>873</td>\n",
       "      <td>984.00</td>\n",
       "      <td>했다. 내가 말하고 싶은 것은 기장이나와 뒤편에 위치해있던 객실승무원의</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038650</th>\n",
       "      <td>873</td>\n",
       "      <td>984.00</td>\n",
       "      <td>했다. 내가 말하고 싶은 것은 기장이나와 뒤편에 위치해있던 객실승무원의 보고에</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1038651 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           i doc_idx                                    candidate  \\\n",
       "0          0    7.00                                     'MAYDAY,   \n",
       "1          0    7.00                             'MAYDAY, MAYDAY,   \n",
       "2          0    7.00                     'MAYDAY, MAYDAY, MAYDAY.   \n",
       "3          0    7.00                 'MAYDAY, MAYDAY, MAYDAY. ABC   \n",
       "4          0    7.00           'MAYDAY, MAYDAY, MAYDAY. ABC 유도로에서   \n",
       "...      ...     ...                                          ...   \n",
       "1038646  873  984.00                       했다. 내가 말하고 싶은 것은 기장이나와   \n",
       "1038647  873  984.00                   했다. 내가 말하고 싶은 것은 기장이나와 뒤편에   \n",
       "1038648  873  984.00             했다. 내가 말하고 싶은 것은 기장이나와 뒤편에 위치해있던   \n",
       "1038649  873  984.00      했다. 내가 말하고 싶은 것은 기장이나와 뒤편에 위치해있던 객실승무원의   \n",
       "1038650  873  984.00  했다. 내가 말하고 싶은 것은 기장이나와 뒤편에 위치해있던 객실승무원의 보고에   \n",
       "\n",
       "         binary_label  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "1038646             0  \n",
       "1038647             0  \n",
       "1038648             0  \n",
       "1038649             0  \n",
       "1038650             0  \n",
       "\n",
       "[1038651 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pair_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f683215-9a9f-4da9-a167-dbf3756cdb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12569"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_pair_dataset_df[\"binary_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb15f0-00d7-43dd-895d-b697973a4436",
   "metadata": {},
   "source": [
    "## (2) 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5427da-b596-4bec-840a-8fb051f5acfc",
   "metadata": {},
   "source": [
    "### (2-1) (사전학습 모델을 통한) Input Document 임베딩 및 Candidate Phrase 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e34e1e-97ac-4270-b7ef-61cd141d0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdd681d3-23a9-4cef-ae20-f2293cf04ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(f'../embeddings/{MODE}/{MODE}_doc_embedding_list.pkl'):\n",
    "    with open(f'../embeddings/{MODE}/{MODE}_doc_embedding_list.pkl', 'rb') as f:\n",
    "        doc_embedding_list = pickle.load(f)\n",
    "else:\n",
    "    doc_embedding_list = [SBERT_model.encode([doc]) for doc in tqdm(train_df[\"본문\"])] # (482, 1, 768)    \n",
    "    with open(f'../embeddings/{MODE}/{MODE}_doc_embedding_list.pkl', 'wb') as f:\n",
    "        pickle.dump(doc_embedding_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539b33c7-ffe0-413e-8fba-d623a046e9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1038651/1038651 [5:38:21<00:00, 51.16it/s] \n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(f'../embeddings/{MODE}/{MODE}_phr_embedding_list_{str(SEQUENCE_MATCHER_THRESHOLD).replace(\".\", \"_\")}.pkl'):\n",
    "    with open(f'../embeddings/{MODE}/{MODE}_phr_embedding_list_{str(SEQUENCE_MATCHER_THRESHOLD).replace(\".\", \"_\")}.pkl', 'rb') as f:\n",
    "        phr_embedding_list = pickle.load(f)\n",
    "else:\n",
    "    phr_embedding_list = [SBERT_model.encode([doc]) for doc in tqdm(train_pair_dataset_df[\"candidate\"])] # (1038651, 1, 768)\n",
    "    with open(f'../embeddings/{MODE}/{MODE}_phr_embedding_list_{str(SEQUENCE_MATCHER_THRESHOLD).replace(\".\", \"_\")}.pkl', 'wb') as f:\n",
    "        pickle.dump(phr_embedding_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d8dfc9-55d3-4465-947d-78f03307f7d6",
   "metadata": {},
   "source": [
    "### (2-2) Embedding Vector들을 Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "827ff72f-297e-4111-b1ef-98ebc908f310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(874, 1038651)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_embedding_list), len(phr_embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "040563d7-3224-4de3-ab56-fe1e875a8d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1038651/1038651 [00:31<00:00, 33000.78it/s]\n"
     ]
    }
   ],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for idx in tqdm(range(len(train_pair_dataset_df))):\n",
    "    concatenated_embedding = np.concatenate((doc_embedding_list[train_pair_dataset_df[\"i\"][idx]], phr_embedding_list[idx]), axis=1)\n",
    "    X_data.append(concatenated_embedding)\n",
    "    y_data.append(train_pair_dataset_df[\"binary_label\"][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b56c5dd-9a1e-4256-8a83-77ca1d26eb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193668/2908007466.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  X_data = torch.tensor(X_data, dtype=torch.float32) # torch.Size([228898, 1, 1536])\n"
     ]
    }
   ],
   "source": [
    "X_data = torch.tensor(X_data, dtype=torch.float32) # torch.Size([228898, 1, 1536])\n",
    "y_data = torch.tensor(y_data, dtype=torch.float32) # torch.Size([228898])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30f0f9-adde-4735-bde1-07bbc6478893",
   "metadata": {},
   "source": [
    "### (2-3) Split Train & Validation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "341c08c0-cc50-4130-af1c-a476d0746759",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, shuffle=False, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2784f8a-c9a1-4c50-99d4-12a1ceeb6a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9989.0, 2580.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train).item(), sum(y_val).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81aa22ff-c8fd-4a79-92e2-a08a8a99c059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830920, 207731)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c9ffa28-6002-4307-9d13-6308e2ff6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = X_train.to(device), X_val.to(device), y_train.to(device), y_val.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c713294-1223-452d-a54d-00e6b318c41d",
   "metadata": {},
   "source": [
    "### (2-4) dataset 및 dataloader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed722e1a-6ef2-4a6a-a430-fc2d66bc90ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d75a3-27c9-4f90-9c90-58dab6e6d59e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (3) Model - Linear Layer (for Binary Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eb22e6d-d226-4f69-bac2-737bbf47217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1536, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.relu(self.bn3(self.fc3(x)))\n",
    "        logit = self.fc4(x)\n",
    "        \n",
    "        return torch.sigmoid(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa8e4ea7-529c-48d1-bde5-6517bf9dd98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=1536, out_features=512, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b01b31-7c1a-434a-86e9-705e01b2d592",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (4) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "470442c9-2324-4855-b95b-529346f17ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eaaf318-cd02-4042-b90d-e4aae20f70a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Training Loss: 0.0324, Training Accuracy: 0.9914, Training Precision: 0.6602, Training Recall: 0.5807, Training F1-score: 0.6179\n",
      "Validation Accuracy: 0.9900, Validation Precision: 0.6171, Validation Recall: 0.5128, Validation F1-score: 0.5601\n",
      "Epoch 2/200\n",
      "Training Loss: 0.0183, Training Accuracy: 0.9910, Training Precision: 0.6394, Training Recall: 0.5835, Training F1-score: 0.6102\n",
      "Validation Accuracy: 0.9895, Validation Precision: 0.5892, Validation Recall: 0.5182, Validation F1-score: 0.5515\n",
      "Epoch 3/200\n",
      "Training Loss: 0.0164, Training Accuracy: 0.9935, Training Precision: 0.7301, Training Recall: 0.7302, Training F1-score: 0.7301\n",
      "Validation Accuracy: 0.9908, Validation Precision: 0.6387, Validation Recall: 0.6023, Validation F1-score: 0.6200\n",
      "Epoch 4/200\n",
      "Training Loss: 0.0150, Training Accuracy: 0.9944, Training Precision: 0.7812, Training Recall: 0.7381, Training F1-score: 0.7590\n",
      "Validation Accuracy: 0.9913, Validation Precision: 0.6714, Validation Recall: 0.5829, Validation F1-score: 0.6241\n",
      "Epoch 5/200\n",
      "Training Loss: 0.0136, Training Accuracy: 0.9944, Training Precision: 0.8562, Training Recall: 0.6416, Training F1-score: 0.7335\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6937, Validation Recall: 0.4767, Validation F1-score: 0.5651\n",
      "Epoch 6/200\n",
      "Training Loss: 0.0123, Training Accuracy: 0.9952, Training Precision: 0.8723, Training Recall: 0.7051, Training F1-score: 0.7798\n",
      "Validation Accuracy: 0.9910, Validation Precision: 0.6863, Validation Recall: 0.5019, Validation F1-score: 0.5798\n",
      "Epoch 7/200\n",
      "Training Loss: 0.0113, Training Accuracy: 0.9964, Training Precision: 0.8650, Training Recall: 0.8258, Training F1-score: 0.8450\n",
      "Validation Accuracy: 0.9910, Validation Precision: 0.6630, Validation Recall: 0.5589, Validation F1-score: 0.6065\n",
      "Epoch 8/200\n",
      "Training Loss: 0.0101, Training Accuracy: 0.9965, Training Precision: 0.8266, Training Recall: 0.9012, Training F1-score: 0.8623\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6294, Validation Recall: 0.6419, Validation F1-score: 0.6356\n",
      "Epoch 9/200\n",
      "Training Loss: 0.0090, Training Accuracy: 0.9973, Training Precision: 0.9180, Training Recall: 0.8557, Training F1-score: 0.8858\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6627, Validation Recall: 0.5384, Validation F1-score: 0.5941\n",
      "Epoch 10/200\n",
      "Training Loss: 0.0078, Training Accuracy: 0.9980, Training Precision: 0.9418, Training Recall: 0.8857, Training F1-score: 0.9129\n",
      "Validation Accuracy: 0.9911, Validation Precision: 0.6727, Validation Recall: 0.5465, Validation F1-score: 0.6031\n",
      "Epoch 11/200\n",
      "Training Loss: 0.0069, Training Accuracy: 0.9981, Training Precision: 0.9197, Training Recall: 0.9207, Training F1-score: 0.9202\n",
      "Validation Accuracy: 0.9908, Validation Precision: 0.6476, Validation Recall: 0.5748, Validation F1-score: 0.6090\n",
      "Epoch 12/200\n",
      "Training Loss: 0.0062, Training Accuracy: 0.9982, Training Precision: 0.8926, Training Recall: 0.9681, Training F1-score: 0.9288\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6344, Validation Recall: 0.6376, Validation F1-score: 0.6360\n",
      "Epoch 13/200\n",
      "Training Loss: 0.0054, Training Accuracy: 0.9987, Training Precision: 0.9301, Training Recall: 0.9654, Training F1-score: 0.9474\n",
      "Validation Accuracy: 0.9910, Validation Precision: 0.6472, Validation Recall: 0.6066, Validation F1-score: 0.6263\n",
      "Epoch 14/200\n",
      "Training Loss: 0.0049, Training Accuracy: 0.9988, Training Precision: 0.9545, Training Recall: 0.9414, Training F1-score: 0.9479\n",
      "Validation Accuracy: 0.9906, Validation Precision: 0.6404, Validation Recall: 0.5543, Validation F1-score: 0.5942\n",
      "Epoch 15/200\n",
      "Training Loss: 0.0045, Training Accuracy: 0.9990, Training Precision: 0.9644, Training Recall: 0.9506, Training F1-score: 0.9575\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6557, Validation Recall: 0.5624, Validation F1-score: 0.6055\n",
      "Epoch 16/200\n",
      "Training Loss: 0.0039, Training Accuracy: 0.9990, Training Precision: 0.9495, Training Recall: 0.9643, Training F1-score: 0.9568\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6399, Validation Recall: 0.5798, Validation F1-score: 0.6084\n",
      "Epoch 17/200\n",
      "Training Loss: 0.0037, Training Accuracy: 0.9991, Training Precision: 0.9603, Training Recall: 0.9646, Training F1-score: 0.9624\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6408, Validation Recall: 0.5752, Validation F1-score: 0.6062\n",
      "Epoch 18/200\n",
      "Training Loss: 0.0034, Training Accuracy: 0.9989, Training Precision: 0.9598, Training Recall: 0.9521, Training F1-score: 0.9560\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6398, Validation Recall: 0.5702, Validation F1-score: 0.6030\n",
      "Epoch 19/200\n",
      "Training Loss: 0.0033, Training Accuracy: 0.9992, Training Precision: 0.9689, Training Recall: 0.9654, Training F1-score: 0.9671\n",
      "Validation Accuracy: 0.9911, Validation Precision: 0.6581, Validation Recall: 0.5849, Validation F1-score: 0.6193\n",
      "Epoch 20/200\n",
      "Training Loss: 0.0030, Training Accuracy: 0.9994, Training Precision: 0.9721, Training Recall: 0.9820, Training F1-score: 0.9770\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6454, Validation Recall: 0.5876, Validation F1-score: 0.6151\n",
      "Epoch 21/200\n",
      "Training Loss: 0.0027, Training Accuracy: 0.9990, Training Precision: 0.9373, Training Recall: 0.9854, Training F1-score: 0.9607\n",
      "Validation Accuracy: 0.9905, Validation Precision: 0.6151, Validation Recall: 0.6194, Validation F1-score: 0.6172\n",
      "Epoch 22/200\n",
      "Training Loss: 0.0026, Training Accuracy: 0.9992, Training Precision: 0.9771, Training Recall: 0.9555, Training F1-score: 0.9661\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6549, Validation Recall: 0.5267, Validation F1-score: 0.5839\n",
      "Epoch 23/200\n",
      "Training Loss: 0.0026, Training Accuracy: 0.9993, Training Precision: 0.9841, Training Recall: 0.9589, Training F1-score: 0.9713\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6502, Validation Recall: 0.5504, Validation F1-score: 0.5961\n",
      "Epoch 24/200\n",
      "Training Loss: 0.0023, Training Accuracy: 0.9996, Training Precision: 0.9848, Training Recall: 0.9820, Training F1-score: 0.9834\n",
      "Validation Accuracy: 0.9910, Validation Precision: 0.6518, Validation Recall: 0.5833, Validation F1-score: 0.6157\n",
      "Epoch 25/200\n",
      "Training Loss: 0.0023, Training Accuracy: 0.9995, Training Precision: 0.9769, Training Recall: 0.9810, Training F1-score: 0.9789\n",
      "Validation Accuracy: 0.9908, Validation Precision: 0.6418, Validation Recall: 0.5957, Validation F1-score: 0.6179\n",
      "Epoch 26/200\n",
      "Training Loss: 0.0021, Training Accuracy: 0.9993, Training Precision: 0.9672, Training Recall: 0.9786, Training F1-score: 0.9729\n",
      "Validation Accuracy: 0.9905, Validation Precision: 0.6226, Validation Recall: 0.6012, Validation F1-score: 0.6117\n",
      "Epoch 27/200\n",
      "Training Loss: 0.0022, Training Accuracy: 0.9995, Training Precision: 0.9763, Training Recall: 0.9810, Training F1-score: 0.9786\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6340, Validation Recall: 0.5969, Validation F1-score: 0.6149\n",
      "Epoch 28/200\n",
      "Training Loss: 0.0020, Training Accuracy: 0.9994, Training Precision: 0.9768, Training Recall: 0.9766, Training F1-score: 0.9767\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6533, Validation Recall: 0.5624, Validation F1-score: 0.6045\n",
      "Epoch 29/200\n",
      "Training Loss: 0.0019, Training Accuracy: 0.9995, Training Precision: 0.9691, Training Recall: 0.9869, Training F1-score: 0.9779\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6311, Validation Recall: 0.5969, Validation F1-score: 0.6135\n",
      "Epoch 30/200\n",
      "Training Loss: 0.0019, Training Accuracy: 0.9996, Training Precision: 0.9810, Training Recall: 0.9838, Training F1-score: 0.9824\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6463, Validation Recall: 0.5822, Validation F1-score: 0.6126\n",
      "Epoch 31/200\n",
      "Training Loss: 0.0017, Training Accuracy: 0.9995, Training Precision: 0.9808, Training Recall: 0.9806, Training F1-score: 0.9807\n",
      "Validation Accuracy: 0.9908, Validation Precision: 0.6524, Validation Recall: 0.5609, Validation F1-score: 0.6032\n",
      "Epoch 32/200\n",
      "Training Loss: 0.0018, Training Accuracy: 0.9994, Training Precision: 0.9902, Training Recall: 0.9614, Training F1-score: 0.9756\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6594, Validation Recall: 0.5171, Validation F1-score: 0.5796\n",
      "Epoch 33/200\n",
      "Training Loss: 0.0017, Training Accuracy: 0.9996, Training Precision: 0.9863, Training Recall: 0.9775, Training F1-score: 0.9818\n",
      "Validation Accuracy: 0.9908, Validation Precision: 0.6464, Validation Recall: 0.5647, Validation F1-score: 0.6028\n",
      "Epoch 34/200\n",
      "Training Loss: 0.0016, Training Accuracy: 0.9997, Training Precision: 0.9879, Training Recall: 0.9853, Training F1-score: 0.9866\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6486, Validation Recall: 0.5465, Validation F1-score: 0.5932\n",
      "Epoch 35/200\n",
      "Training Loss: 0.0017, Training Accuracy: 0.9996, Training Precision: 0.9792, Training Recall: 0.9882, Training F1-score: 0.9837\n",
      "Validation Accuracy: 0.9907, Validation Precision: 0.6283, Validation Recall: 0.6178, Validation F1-score: 0.6230\n",
      "Epoch 36/200\n",
      "Training Loss: 0.0015, Training Accuracy: 0.9996, Training Precision: 0.9850, Training Recall: 0.9859, Training F1-score: 0.9854\n",
      "Validation Accuracy: 0.9909, Validation Precision: 0.6448, Validation Recall: 0.5930, Validation F1-score: 0.6178\n",
      "Epoch 37/200\n",
      "Training Loss: 0.0016, Training Accuracy: 0.9996, Training Precision: 0.9883, Training Recall: 0.9819, Training F1-score: 0.9851\n",
      "Validation Accuracy: 0.9908, Validation Precision: 0.6461, Validation Recall: 0.5733, Validation F1-score: 0.6075\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "train_loss_values = []  # To store training loss for each epoch\n",
    "val_accuracy_values = []  # To store validation accuracy for each epoch\n",
    "val_probabilities = []  # To store probabilities of the positive class for each validation sample\n",
    "\n",
    "best_val_recall = 0.0\n",
    "patience = 30  # Number of epochs to wait before early stopping\n",
    "no_improvement_count = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # H(x) 계산\n",
    "        logits = model(inputs)\n",
    "\n",
    "        # loss 계산\n",
    "        loss = criterion(logits.view(-1), labels)\n",
    "\n",
    "        # loss로 H(x) 계산\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    # Compute training accuracy for the epoch\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        train_outputs = model(X_train)\n",
    "        train_predictions = (train_outputs >= 0.5).long().view(-1).cpu()\n",
    "        train_accuracy = accuracy_score(y_train.cpu(), train_predictions)\n",
    "        train_precision = precision_score(y_train.cpu(), train_predictions)\n",
    "        train_recall = recall_score(y_train.cpu(), train_predictions)\n",
    "        train_f1 = f1_score(y_train.cpu(), train_predictions)\n",
    "        train_loss_values.append(total_loss / len(train_loader))\n",
    "\n",
    "        # Validation loop for computing validation accuracy, precision, recall, and F1-score\n",
    "        val_outputs = model(X_val)\n",
    "        val_predictions = (val_outputs >= 0.5).long().view(-1).cpu()\n",
    "        val_accuracy = accuracy_score(y_val.cpu(), val_predictions)\n",
    "        val_precision = precision_score(y_val.cpu(), val_predictions)\n",
    "        val_recall = recall_score(y_val.cpu(), val_predictions)\n",
    "        val_f1 = f1_score(y_val.cpu(), val_predictions)\n",
    "        val_accuracy_values.append(val_accuracy)\n",
    "\n",
    "        # Save the model with the best validation recall\n",
    "        if val_recall > best_val_recall:\n",
    "            best_val_recall = val_recall\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            \n",
    "        # Early stopping\n",
    "        if no_improvement_count >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "            \n",
    "        # Calculate probabilities of the positive class (class 1) for each validation sample\n",
    "        val_probabilities.append(val_outputs.squeeze().tolist())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\\n\"\n",
    "              f\"Training Loss: {train_loss_values[-1]:.4f}, \"\n",
    "              f\"Training Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Training Precision: {train_precision:.4f}, \"\n",
    "              f\"Training Recall: {train_recall:.4f}, \"\n",
    "              f\"Training F1-score: {train_f1:.4f}\\n\"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, \"\n",
    "              f\"Validation Precision: {val_precision:.4f}, \"\n",
    "              f\"Validation Recall: {val_recall:.4f}, \"\n",
    "              f\"Validation F1-score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8779c09-016b-4e86-be62-42d1699b07b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (5) 모델 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77d67a90-a25b-4db3-856a-82cb4c3419c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1536, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.relu(self.bn3(self.fc3(x)))\n",
    "        logit = self.fc4(x)\n",
    "        \n",
    "        return torch.sigmoid(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a5a3920-02e2-45fc-87e5-630e2022da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33a3b0d1-737f-4e7a-a4f7-1fe2c3b777df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=1536, out_features=512, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3dfcdd-fcdc-4e61-b0e4-4b359cd3eae8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (6) 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31269611-2ded-4c9c-9961-578c664383e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_range = (MIN_NGRAM, MAX_NGRAM)\n",
    "n_gram_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5de091c1-b820-417b-b8a9-342401221243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(doc):\n",
    "    processed_doc = doc.strip('\"').replace(\"\\n\", \" \").strip()\n",
    "    processed_doc = re.sub('\\s+', ' ', processed_doc)\n",
    "    \n",
    "    return processed_doc\n",
    "\n",
    "def tokenizer(string):\n",
    "    return string.split(\" \")\n",
    "\n",
    "def inference(doc_text, return_prob=False, fail_return=False):\n",
    "    \"\"\"\n",
    "    doc_text (str) : 추론할 보고서\n",
    "    return_prob (bool) : 예측 확률까지 같이 return 할지에 대한 여부\n",
    "    fail_return (bool) : 원인 분석에 실패했을때, 그나마 가능성 있는 top5를 return 할지에 대한 여부\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_doc = process_doc(doc_text)\n",
    "    tokenized_doc = \" \".join(processed_doc.split(' '))\n",
    "    \n",
    "    count = CountVectorizer(ngram_range=n_gram_range, lowercase=False, tokenizer=tokenizer, token_pattern=None).fit([tokenized_doc])    \n",
    "    candidates = count.get_feature_names_out()\n",
    "    \n",
    "    test_doc_embedding = SBERT_model.encode([doc_text])\n",
    "    test_phr_embedding_list = [SBERT_model.encode([phr]) for phr in (candidates)]\n",
    "    \n",
    "    X_test = []\n",
    "    for test_phr_embedding in (test_phr_embedding_list):\n",
    "        concatenated_embedding = np.concatenate((test_doc_embedding, test_phr_embedding), axis=1)\n",
    "        X_test.append(concatenated_embedding)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    \n",
    "    test_probabilities = []  # To store probabilities of the positive class for each test sample\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        # Test loop for computing test_predictions & test_probabilities\n",
    "        test_outputs = model(X_test)\n",
    "        test_predictions = (test_outputs >= 0.5).long().view(-1).cpu()\n",
    "        test_probabilities.append(test_outputs.squeeze().tolist()) # Calculate probabilities of the positive class (class 1) for each test sample\n",
    "        \n",
    "    # Convert probabilities tensor to a numpy array\n",
    "    probabilities = np.array(test_probabilities)[0]\n",
    "\n",
    "    # Filter candidates with probabilities greater than or equal to 0.5\n",
    "    filtered_candidates = candidates[probabilities >= 0.5]\n",
    "    filtered_probabilities = probabilities[probabilities >= 0.5]\n",
    "\n",
    "    # Sort candidates in descending order based on probabilities\n",
    "    sorted_indices = np.argsort(filtered_probabilities)[::-1]\n",
    "    sorted_candidates = filtered_candidates[sorted_indices]\n",
    "    sorted_probabilities = filtered_probabilities[sorted_indices]\n",
    "\n",
    "    \n",
    "    if return_prob==True:\n",
    "        predicted_phrases_and_prob_list = []\n",
    "\n",
    "        # Check if there are candidates with probabilities greater than or equal to 0.5\n",
    "        if len(sorted_candidates) > 0:\n",
    "            # Print the sorted candidates and their corresponding probabilities\n",
    "            for candidate, probability in zip(sorted_candidates, sorted_probabilities):\n",
    "                predicted_phrases_and_prob_list.append( (candidate, probability) )\n",
    "                # print(f\"Predicted Keyphrase: '{candidate}', Probability: {probability:.6f}\")\n",
    "        else:\n",
    "            if fail_return == True:\n",
    "                predicted_phrases_and_prob_list.append( (\"KEYPHRASE_PREDICTION_FAILED!\", 0) )\n",
    "\n",
    "                # If no candidates with probabilities >= 0.5, print top 5 candidates with the highest probabilities\n",
    "                top_5_indices = np.argsort(probabilities)[::-1][:5]\n",
    "                top_5_candidates = candidates[top_5_indices]\n",
    "                top_5_probabilities = probabilities[top_5_indices]\n",
    "\n",
    "                for candidate, probability in zip(top_5_candidates, top_5_probabilities):\n",
    "                    predicted_phrases_and_prob_list.append( (candidate, probability) )\n",
    "                    # print(f\"Top-5 Candidate: '{candidate}', Probability: {probability:.6f}\")\n",
    "\n",
    "        return predicted_phrases_and_prob_list\n",
    "    \n",
    "    else:\n",
    "        predicted_phrases_list = []\n",
    "\n",
    "        # Check if there are candidates with probabilities greater than or equal to 0.5\n",
    "        if len(sorted_candidates) > 0:\n",
    "            # Print the sorted candidates and their corresponding probabilities\n",
    "            for candidate, probability in zip(sorted_candidates, sorted_probabilities):\n",
    "                predicted_phrases_list.append( candidate )\n",
    "                # print(f\"Predicted Keyphrase: '{candidate}', Probability: {probability:.6f}\")\n",
    "        else:\n",
    "            if fail_return == True:\n",
    "                predicted_phrases_list.append( (\"KEYPHRASE_PREDICTION_FAILED!\", 0) )\n",
    "\n",
    "                # If no candidates with probabilities >= 0.5, print top 5 candidates with the highest probabilities\n",
    "                top_5_indices = np.argsort(probabilities)[::-1][:5]\n",
    "                top_5_candidates = candidates[top_5_indices]\n",
    "                top_5_probabilities = probabilities[top_5_indices]\n",
    "\n",
    "                for candidate, probability in zip(top_5_candidates, top_5_probabilities):\n",
    "                    predicted_phrases_list.append( candidate )\n",
    "                    # print(f\"Top-5 Candidate: '{candidate}', Probability: {probability:.6f}\")\n",
    "\n",
    "        return predicted_phrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e83669f2-51de-49b7-bd77-1659a4e144ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text = \"\"\"- 00비행장에서 IFR(Instrument Flight Rules, 계기비행 규칙) 비행으로 초기 상승 중이었던 항공기 A에 대해, 주변의 최저 유도 고도*(MVA: Minimum Vectoring Altitude)를 혼동하여 당시 고도 약 4,000ft에 있던 항공기를 해당 MVA (약 5,000ft) 미만에서 레이더 유도하였던 내용에 대한 자율 보고서임.\n",
    "* 최저 유도 고도(MVA): 항공교통 관제 기관이 안전한 레이더 관제를 실시하는 데 활용하기 위해 설정한 고도로, 가장 높은 장애물로부터 1,000ft의 분리(비산악 지역), 또는 2,000ft의 분리(산악 지역)가 적용되며, 적절한 레이더 송/수신 보장, 해당 관제 공역의 최저점으로부터 최소 300ft의 분리 등의 조건을 만족하는 고도이다.\n",
    "- 항공기 A는 표준 계기 출발 절차(SID: Standard Instrument Departure)를 수행 중이었으며, 보고자는 접근 관제 업무 한정을 취득하고자 하는 관제 훈련생을 대상으로 뒤에서 모니터하며 관제 업무를 수행 중이었음. 항공기 A에 대한 관제 업무 한정을 취득하고자 하는 관제 훈련생을 대상으로 뒤에서 모니터하며 관제 업무를 수행 중이었음. 항공기 A에 대한 관제권을 인수하기 전, 협조석* 관제사로부터 출발 경로, SID 및 비행 계획에 관한 정보를 전달받아 해당 항공기를 감시 중이었음.\n",
    "* 협조석 관제사(Coordination 또는 Flight Data 관제사) : 타 관제 기관 또는 동일 관제 기관 내 좌석 간의 이양/인수 등 협조가 필요한 사항 및 필요한 정보를 전달해주는 역할을 수행하는 관제사\n",
    "- 최초 교신 당시에 항공기 A의 선회 반경이 예정 경로보다 작았고(통상적인 항공기보다 속도가 느려서), 이에 따라 출발 절차에 규정된 첫 번째 고도 제한(5,000ft 이상 7,000ft 이하)을 간신히 통과할 것으로 판단하였고, 두 번째 고도 제한(9,000ft 이상) 준수는 불가능할 것으로 판단하였음. 또한 항공기와 인접한 MVA가 7,000ft 이상으로 구성되어, 해당 영역에 진입 시 레이더 유도를 통한 항공기 안전을 담보할 수 없는 상황이었음(MVA 미만의 고도에 항공기가 위치하므로 레이더 유도 불가).\n",
    "- 또한 00비행장에 설정된 다른 계기 출발 절차와는 상이하게, 목적지 공항 방향이 아닌 고고도 장애물 방향으로 경로가 설정되어 교통 흐름이 효율적이지 못했고, 해당 항공기가 저속이기 때문에 다른 항공기의 IFR 운항에 제한을 줄 수 있었음.\n",
    "- 이에 따라 고고도 장애물 방향으로 진행하던 표준 계기 출발 절차를 취소하고, MVA가 낮은 북쪽 공역으로 레이더 유도를 하도록 관제 훈련생에게 지시하였음. 이때 항공기 A가 위치한 공역의 MVA(5,000ft)가 아닌, 북쪽의 인접한 공역의 MVA(약 3,000ft)에 해당한다고 착각하여, 항공기의 현 고도가 MVA 미만임에도 불구하고 레이더 유도를 실시하여 최저 유도 고도 미만에서의 레이더 유도가 이루어짐.\n",
    "- (보고자 의견) 최근 관할 TMA(Terminal Control Area, 접근 관제 구역) 내 MVA가 전반적으로 상향되었으나, 인근 공항(비행장)에서 사용 중인 비행 절차는 이를 반영하지 못한 절차가 다수 있다고 사료되어, 관계 기관 간의 논의를 통해 항공교통 안전 및 원활한 교통 흐름이 보장되는 계기 절차의 개정이 이루어지길 바람.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d83b8c01-7109-4794-9037-59723c743062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a6e8904-d1be-475e-9d8c-5e7a1bb6a130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_text = \"\"\"- ○○비행장에서 이륙을 위하여 활주로 정지선 전에 대기한 후 관제탑에 이륙 허가를 요청하였음.\n",
    "- 관제사로부터 이륙 허가를 받고 난 직후, 활주로에 진입하기 위한 절차를 수행하며 Final leg(비행장에 시계비행으로 접근하기 위한 사각형의 비행 장주 중, 착륙하기 위해 활주로에 정대하는 최종 구간)를 육안으로 확인하던 중, 약 0.5NM에 접근하는 항공기를 확인하여 관제사에게 이를 보고하였음.\n",
    "- 이를 보고하자, 관제사는 즉시 이륙 허가를 취소했고, 접근하던 항공기는 이 교신을 듣고 직접 복행하였음.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1623292-fa6c-478d-ba54-f1ca8756a915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aec3cba3-f6bb-4beb-bc41-6a84b469bf18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_text = \"\"\"항공편은 만석이었습니다. 객실 승무원은 세 명으로, 그중 한 명은 신입이었습니다. 해당 항공편은 이미 90분가량 지연된 상황이었습니다. 좌석 위 선반은 금방 차 버려, 승객들이 안내에 따라 가방을 수납하도록 여러 차례 기내 방송을 했습니다. \n",
    "탑승이 끝났을 때 여행 가방 5개가량이 수납되지 못한 상황이었기 때문에, 신입 승무원에게 객실에 수납공간을 만들어 보라고 말했습니다. 나머지 두 명은 출입문을 지켜야 했습니다.\n",
    "지상 근무 직원들은 출입구 옆에 서서 제가 수화물 반출 여부를 결정할 때까지 기다렸습니다. 하지만 저는 개방된 출입구 앞 위치를 지켜야 했기 때문에, 서 있는 자리에서 최선의 추측을 해야 했습니다. 만약 제가 도어를 오픈 상태로 유지하라 했다가 짐을 내리지 않게 되면 항공기 지연의 책임은 제가 지게 되며, 이에 대한 “관리”를 받게 됩니다. 이렇듯 지연을 발생시키지 말라는 항공사의 압력이 은근히 존재합니다. 결국 저는 직원들에게 출입문을 닫으라고 지시했습니다. \n",
    "객실 승무원 세 명 모두가 객실에서 기내 수화물 정리에 매달리느라 아무도 출입구를 지키지 못한 때도 있었습니다. 저희는 통로에 있던 짐을 모두 수납하는 데 간신히 성공했습니다. \n",
    "안전 수칙 시범을 끝내고 이륙 준비를 시작하던 중, 승객이 다리 뒤에 숨기고 있던 바퀴 달린 여행 가방 하나와 비상 열의 승객들이 다리 뒤에 두었던 대형 배낭 두 개를 발견했습니다. 여행 가방은 완전히 포화 상태가 된 옷장에, 배낭 두 개는 좌석 위 선반 안에 가까스로 밀어 넣었습니다. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3a75fe3-efb4-46d2-a76d-46e6a3d88433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(doc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f995b-6fdc-4ff0-b0d2-bc69055d20fd",
   "metadata": {},
   "source": [
    "## (7) 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710a45b-5bfd-4d01-a147-b54ce42f857d",
   "metadata": {},
   "source": [
    "testset 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d99b95ac-141b-48b9-9700-9ededef52047",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/rawdata/GYRO_testset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "defad92e-7b21-4728-affb-016f2a0c732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 219/219 [52:44<00:00, 14.45s/it] \n"
     ]
    }
   ],
   "source": [
    "predicted_keyphrases_list = []\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    doc = test_df[\"본문\"][i]\n",
    "    predicted_keyphrase = inference(doc)\n",
    "    predicted_keyphrases_list.append('\"' + '\", \"'.join(predicted_keyphrase) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ec92b2a-856a-4044-9eda-28470906c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"SBERT 예측 키워드\"] = predicted_keyphrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bb2134f-4812-4f3f-a5e7-b8aca7913af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../data/prediction/SBERT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fb8f25a-186e-4402-8f79-5ecfcce75803",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be43e95-ca17-4808-a677-301c92338294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
